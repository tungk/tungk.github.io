<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tung Kieu</title>
    <link>https://tungk.github.io/</link>
    <description>Recent content on Tung Kieu</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Sep 2024 03:09:12 +0200</lastBuildDate>
    <atom:link href="https://tungk.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Combining One-Class Classifiers via Meta Learning</title>
      <link>https://tungk.github.io/posts/combining-one-class-classifiers-via-meta-learning/</link>
      <pubDate>Mon, 16 Sep 2024 03:09:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/combining-one-class-classifiers-via-meta-learning/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Selecting the best classifier among the available ones is a difficult task, especially when only instances of one class exist. In this work we examine the notion of combining one-class classifiers as an alternative for selecting the best classifier. In particular, we propose two one-class classification performance measures to weigh classifiers and show that a simple ensemble that implements these measures can outperform the most popular one-class ensembles. Furthermore, we propose a new one-class ensemble scheme, &lt;strong&gt;TUPSO&lt;/strong&gt;, which uses meta-learning to combine one-class classifiers. Our experiments demonstrate the superiority of &lt;strong&gt;TUPSO&lt;/strong&gt; over all other tested ensembles and show that the &lt;strong&gt;TUPSO&lt;/strong&gt; performance is statistically indistinguishable from that of the hypothetical best classifier.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modeling Extreme Events in Time Series Prediction</title>
      <link>https://tungk.github.io/posts/modeling-extreme-events-in-time-series-prediction/</link>
      <pubDate>Mon, 16 Sep 2024 03:06:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/modeling-extreme-events-in-time-series-prediction/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Recent deep learningbased methods overlook the existence of extreme events, which result in weak performance when applying them to real time series. Extreme events are rare and random, but do play a critical role in many real applications, such as the forecasting of financial crisis and natural disasters. In this paper, the authors &lt;strong&gt;explore the central theme of improving the ability of deep learning on modeling extreme events for time series prediction&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepGPD: A Deep Learning Approach for Modeling Geospatio-Temporal Extreme Events</title>
      <link>https://tungk.github.io/posts/deepgpd_-a-deep-learning-approach-for-modeling-geospatio-temporal--extreme-events/</link>
      <pubDate>Mon, 16 Sep 2024 03:05:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/deepgpd_-a-deep-learning-approach-for-modeling-geospatio-temporal--extreme-events/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Geospatio-temporal data are pervasive across numerous application domains. These rich datasets can be harnessed to predict extreme events such as disease outbreaks, ﬂooding,  crime spikes, etc.&lt;/p&gt;&#xA;&lt;p&gt;Statistical methods based on extreme value theory provide a systematic way for modeling the distribution of extreme values. In particular, the generalized Pareto distribution (GPD) is useful for modeling the distribution of excess values above a certain threshold. However, applying such methods to large-scale spatio-temporal data is a challenge due to the difﬁculty in capturing the complex spatial relationships between extreme events at multiple locations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Online Algorithm for Segmenting Time Series</title>
      <link>https://tungk.github.io/posts/an-online-algorithm-for-segmenting-time-series/</link>
      <pubDate>Mon, 16 Sep 2024 03:01:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/an-online-algorithm-for-segmenting-time-series/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Intuitively Piecewise Linear Representation refers to the approximation of a time series $T$, of length $n$, with $K$ straight lines. Because $K$ is typically muchsmaller that $n$, this representation makes the storage, transmission and computation of the data more efficient.&lt;/p&gt;&#xA;&lt;p&gt;The segmentation problem can be framed in several ways.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Given a time series $T$, produce the best representation using only $K$ segments.&lt;/li&gt;&#xA;&lt;li&gt;Given a time series $T$, produce the best representation such that the maximum error for any segment does not exceed some user-specified threshold, &lt;code&gt;max_error&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Given a time series $T$, produce the best representation such that the combined error of all segments is less than some user-specified threshold, &lt;code&gt;total_max_error&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Although appearing under different names and with slightly different implementation details,&#xA;most time series segmentation algorithms can be grouped into one of the following three&#xA;categories.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepExtrema: A Deep Learning Approach for Forecasting Block Maxima</title>
      <link>https://tungk.github.io/posts/deepextrema_-a-deep-learning-approach-for-forecasting-block-maxima/</link>
      <pubDate>Mon, 16 Sep 2024 02:55:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/deepextrema_-a-deep-learning-approach-for-forecasting-block-maxima/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;This paper presents &lt;strong&gt;DeepExtrema&lt;/strong&gt;, a novel framework that combines a deep neural network (DNN) with generalized extreme value (GEV) distribution to forecast the block maximum value of a time se- ries. Implementing such a network is a challenge as the framework must preserve the inter-dependent constraints among the GEV model parameters even when the DNN is initialized.&lt;/p&gt;&#xA;&lt;p&gt;The authors describe our approach to address this challenge and present an architecture that enables both conditional mean and quantile prediction of the block maxima.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Composed Video Retrieval via Enriched Context and Discriminative Embeddings</title>
      <link>https://tungk.github.io/posts/composed-video-retrieval-via-enriched-context-and-discriminative-embeddings/</link>
      <pubDate>Wed, 26 Jun 2024 23:55:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/composed-video-retrieval-via-enriched-context-and-discriminative-embeddings/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Composed video retrieval (CoVR) is a challenging problem in computer vision which has recently highlighted the integration of modification text with visual queries for more sophisticated video search in large databases. Existing works predominantly rely on visual queries combined with modification text to distinguish relevant videos. However, such a strategy struggles to fully preserve the rich query-specific context in retrieved target videos and only represents the target video using visual embedding. We introduce a novel CoVR framework that leverages detailed language descriptions to explicitly encode query-specific contextual information and learns discriminative embeddings of vision only, text only and vision-text for better alignment to accurately retrieve matched target videos. Our proposed framework can be flexibly employed for both composed video (CoVR) and image (CoIR) retrieval tasks. Experiments on three datasets show that our approach obtains state-of-the-art performance for both CovR and zero-shot CoIR tasks, achieving gains as high as around 7% in terms of recall@K=1 score&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-Trained One-class Classification for Unsupervised Anomaly Detection</title>
      <link>https://tungk.github.io/posts/self-trained-one-class-classification-for-unsupervised-anomaly-detection/</link>
      <pubDate>Sat, 22 Jun 2024 19:43:19 +0200</pubDate>
      <guid>https://tungk.github.io/posts/self-trained-one-class-classification-for-unsupervised-anomaly-detection/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;In this work, we focus on unsupervised AD problems whose entire training data are unlabeled and may contain both normal and anomalous samples. To tackle this problem, we build a robust one-class classification framework via data refinement. To refine the data accurately, we propose an ensemble of one-class classifiers, each of which is trained on a disjoint subset of training data. Moreover, we propose a self-training of deep representation one-class classifiers (STOC) that iteratively refines the data and deep representations. In experiments, we show the efficacy of our method for unsupervised anomaly detection on benchmarks from image and tabular data domains. For example, with a \(10\%\) anomaly ratio on CIFAR-10 data, the proposed method outperforms state-of-the-art one-class classification method by \(6.3\) AUC and \(12.5\) average precision.&lt;/p&gt;</description>
    </item>
    <item>
      <title>HDC-MiniROCKET: Explicit Time Encoding in Time Series Classification with Hyperdimensional Computing</title>
      <link>https://tungk.github.io/posts/hdc-mini_rocket-explicit-time-encoding-in-time-series-classification-with-hyperdimensional-computing/</link>
      <pubDate>Sat, 22 Jun 2024 14:55:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/hdc-mini_rocket-explicit-time-encoding-in-time-series-classification-with-hyperdimensional-computing/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Classification of time series data is an important task for many application domains. One of the best existing methods for this task, in terms of accuracy and computation time, is MiniROCKET. In this work, we extend this approach to provide better global temporal encodings using hyperdimensional computing (HDC) mechanisms. HDC (also known as Vector Symbolic Architectures, VSA) is a general method to explicitly represent and process information in high-dimensional vectors. It has previously been used successfully in combination with deep neural networks and other signal processing algorithms. We argue that the internal high-dimensional representation of MiniROCKET is well suited to be complemented by the algebra of HDC. This leads to a more general formulation, HDC-MiniROCKET, where the original algorithm is only a special case. We will discuss and demonstrate that HDC-MiniROCKET can systematically overcome catastrophic failures of MiniROCKET on simple synthetic datasets. These results are confirmed by experiments on the 128 datasets from the UCR time series classification benchmark. The extension with HDC can achieve considerably better results on datasets with high temporal dependence without increasing the computational effort for inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robustness of Autoencoders for Anomaly Detection Under Adversarial Impact</title>
      <link>https://tungk.github.io/posts/robustness-of-autoencoders-for-anomaly-detection-under-adversarial-impact/</link>
      <pubDate>Sat, 22 Jun 2024 01:20:14 +0200</pubDate>
      <guid>https://tungk.github.io/posts/robustness-of-autoencoders-for-anomaly-detection-under-adversarial-impact/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Deep learning methods have achieved state-of-the-art performance in anomaly detection in recent years; unsupervised methods being particularly popular. However, deep learning methods can be fragile to small perturbations in the input data. This phenomena has been widely studied in the context of supervised image classification since its discovery, however such studies for an anomaly detection setting are sorely lacking. Moreover, the plethora of defense mechanisms that have been proposed are often not applicable to unsupervised anomaly detection models&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stichable Neural Networks</title>
      <link>https://tungk.github.io/posts/stichable-neural-networks/</link>
      <pubDate>Fri, 21 Jun 2024 23:55:12 +0200</pubDate>
      <guid>https://tungk.github.io/posts/stichable-neural-networks/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;&#xD;&#xA;  Abstract&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#abstract&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;As each model family consists of pretrained models with diverse scales (e.g.,&#xA;DeiT-Ti/S/B), it naturally arises a fundamental question of how to efficiently assemble these readily available models in a family for dynamic accuracy-efficiency trade-offs at runtime.&lt;/p&gt;&#xA;&lt;p&gt;The paper presents Stitchable Neural Networks (&lt;strong&gt;SN-Net&lt;/strong&gt;), a novel scalable and efficient framework for model deployment. It cheaply produces numerous networks with different complexity and performance trade-offs given a family of pretrained neural networks, which are called &lt;strong&gt;anchors&lt;/strong&gt;. Specifically, SN-Net splits the anchors across the blocks/layers and then stitches them together with simple stitching layers to map the activations from one anchor to another. With only a few epochs of training, SN-Net effectively interpolates between the performance of anchors with varying scales. At runtime, SN-Net can instantly adapt to dynamic resource constraints by switching the stitching positions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Profile</title>
      <link>https://tungk.github.io/pages/profile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tungk.github.io/pages/profile/</guid>
      <description>&lt;h2 id=&#34;contact-information&#34;&gt;&#xD;&#xA;  Contact Information&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contact-information&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Office&lt;/strong&gt;: (1) A.C. Meyers Vaenge 15, Room 2.095, Copenhagen, Denmark; (2) Selma Lagerlofs Vej 300, Room 3-2-05, Aalborg, Denmark&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Email&lt;/strong&gt;: (1) tungkvt[at]cs[dot]aau[dot]dk; (2) kvttung[at]gmail[dot]com&lt;/p&gt;&#xA;&lt;h2 id=&#34;biography&#34;&gt;&#xD;&#xA;  Biography&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#biography&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;I am an Assistant Professor in the &lt;em&gt;Department of Computer Science&lt;/em&gt; at &lt;em&gt;Aalborg University&lt;/em&gt;. I am a faculty member in &lt;em&gt;Center for Data-Intensive Systems&lt;/em&gt;. I am also affiliated with the department&amp;rsquo;s team on Artificial Intelligence and Machine Learning and the university&amp;rsquo;s &lt;em&gt;Center on AI for the People&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Publication</title>
      <link>https://tungk.github.io/pages/publication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tungk.github.io/pages/publication/</guid>
      <description>&lt;h2 id=&#34;selected-publication&#34;&gt;&#xD;&#xA;  Selected Publication&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#selected-publication&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Buang Zhang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Xiangfei Qiu, Chenjuan Guo, Jilin Hu, Aoying Zhou, Christian S. Jensen, and Bin Yang. &lt;em&gt;An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data&lt;/em&gt;. IEEE International Conference on Data Engineering&amp;mdash;&lt;strong&gt;ICDE&lt;/strong&gt; 2026 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Nghiem Thanh Pham, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Duc-Manh Nguyen, Son Ha Xuan, Nghia Duong-Trung, and Danh Le-Phuoc. &lt;em&gt;SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impact&lt;/em&gt;. International Conference on Empirical Methods in Natural Language Processing&amp;mdash;&lt;strong&gt;EMNLP&lt;/strong&gt; 2025 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Huy Le, Nhat Chung, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Anh Nguyen, and Ngan Le. &lt;em&gt;BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance&lt;/em&gt;. ACM International Conference on Multimedia&amp;mdash;&lt;strong&gt;MM&lt;/strong&gt; 2025 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Duc Kieu, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Peng Han, Bin Yang, Christian S. Jensen, and Bac Le. &lt;em&gt;TEAM: Topological Evolution-aware Framework for Traffic Forecasting&lt;/em&gt;. International Conference on Very Large Data Bases&amp;mdash;&lt;strong&gt;VLDB&lt;/strong&gt; 2025 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;David Campos, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Miao Zhang, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;QCore: Data-Efficient, On-Device Continual Calibration for Quantized Models&lt;/em&gt;. International Conference on Very Large Data Bases&amp;mdash;&lt;strong&gt;VLDB&lt;/strong&gt; 2024 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Chenjuan Guo, Ronghui Xu, Yuan Ye, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Yan Zhao, and Christian S. Jensen. &lt;em&gt;Efficient Stochastic Routing in Path-Centric Uncertain Road Networks&lt;/em&gt;. International Conference on Very Large Data Bases&amp;mdash;&lt;strong&gt;VLDB&lt;/strong&gt; 2024 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Huy Le, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Anh Nguyen, and Ngan Le. &lt;em&gt;WAVER: Writing-style Agnostic Video Retrieval via Distilling Vision-Language Models Through Open-Vocabulary Knowledge&lt;/em&gt;. IEEE International Conference on Acoustics, Speech, and Signal Processing&amp;mdash;&lt;strong&gt;ICASSP&lt;/strong&gt; 2024 (&lt;strong&gt;CORE A&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;David Campos, Miao Zhang, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;LightTS: Lightweight Time Series Classification with Adaptive Ensemble Distillation&lt;/em&gt;. ACM International Conference on Management of Data&amp;mdash;&lt;strong&gt;SIGMOD&lt;/strong&gt; 2023 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Razvan-Gabriel Cirstea, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Xuanyi Dong, Shirui Pan, and Bin Yang. &lt;em&gt;Triformer: Triangular, Variable-Specific Attention for Long Sequence Multivariate Time Series Forecasting&lt;/em&gt;. International Joint Conference on Artificial Intelligence&amp;mdash;&lt;strong&gt;IJCAI&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Razvan-Gabriel Cirstea, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Shirui Pan, and Bin Yang. &lt;em&gt;Towards Spatio-Temporal Aware Traffic Time Series Forecasting&lt;/em&gt;. IEEE International Conference on Data Engineering&amp;mdash;&lt;strong&gt;ICDE&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, Chenjuan Guo, Christian S. Jensen, Yan Zhao, Feiteng Huang, and Kai Zheng. &lt;em&gt;Robust and Explainable Autoencoders for Time Series Outlier Detection&lt;/em&gt;. IEEE International Conference on Data Engineering&amp;mdash;&lt;strong&gt;ICDE&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, Chenjuan Guo, Razvan-Gabriel Cirstea, Yan Zhao, Yale Song, and Christian S. Jensen. &lt;em&gt;Anomaly Detection in Time Series with Robust Variational Quasi-Recurrent Autoencoders&lt;/em&gt;. IEEE International Conference on Data Engineering&amp;mdash;&lt;strong&gt;ICDE&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Yan Zhao, Xuanhao Chen, Liwei Deng, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Bin Yang, Kai Zheng, and Christian S. Jensen. &lt;em&gt;Outlier Detection for Streaming Task Assignment in Crowdsourcing&lt;/em&gt;. ACM The Web Conference&amp;mdash;&lt;strong&gt;WWW&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*).&lt;/li&gt;&#xA;&lt;li&gt;David Campos, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Feiteng Huang, Kai Zheng, Bin Yang, and Christian S. Jensen. &lt;em&gt;Unsupervised Time Series Outlier Detection with Diversity-Driven Convolutional Ensembles&lt;/em&gt;. International Conference on Very Large Data Bases&amp;mdash;&lt;strong&gt;VLDB&lt;/strong&gt; 2022 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;Razvan-Gabriel Cirstea, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Bin Yang, and Sinno Jialin Pan. &lt;em&gt;EnhanceNet: Plugin Neural Networks for Enhancing Correlated Time Series Forecasting&lt;/em&gt;. IEEE International Conference on Data Engineering&amp;mdash;&lt;strong&gt;ICDE&lt;/strong&gt; 2021 (&lt;strong&gt;CORE A&lt;/strong&gt;*).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;Outlier Detection for Time Series with Recurrent Autoencoder Ensembles&lt;/em&gt;. International Joint Conference on Artificial Intelligence&amp;mdash;&lt;strong&gt;IJCAI&lt;/strong&gt; 2019 (&lt;strong&gt;CORE A&lt;/strong&gt;*)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;Distinguishing Trajectories from Different Drivers using Incompletely Labeled Trajectories&lt;/em&gt;. ACM International Conference on Information and Knowledge Management&amp;mdash;&lt;strong&gt;CIKM&lt;/strong&gt; 2018 (&lt;strong&gt;CORE A&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, and Christian S. Jensen. &lt;em&gt;Outlier Detection for Multidimensional Time Series Using Deep Neural Networks&lt;/em&gt;. IEEE International Conference on Mobile Data Management&amp;mdash;&lt;strong&gt;MDM&lt;/strong&gt; 2018 (&lt;strong&gt;CORE B&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Toan Nguyen, Duc Kieu, Bao Duong, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Kien Do, Thin Nguyen, and Bac Le. &lt;em&gt;Class-incremental Learning with Causal Relational Replay&lt;/em&gt;. &lt;strong&gt;Expert Syst. Appl.&lt;/strong&gt; 250 2024&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bay Vo, Tuong Le, Zhi-Hong Deng, and Bac Le. &lt;em&gt;Mining Top-k Co-occurrence Items with Sequential Pattern&lt;/em&gt;. &lt;strong&gt;Expert Syst. Appl.&lt;/strong&gt; 85 2017&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;preprint&#34;&gt;&#xD;&#xA;  Preprint&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#preprint&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Buang Zhang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Xiangfei Qiu, Chenjuan Guo, Jilin Hu, Aoying Zhou, Christian S. Jensen, and Bin Yang. &lt;em&gt;An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data&amp;ndash;Extended Version&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Duc Kieu, Kien Do, Tuan Hoang, Thao Minh Le, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Dang Nguyen, and Thin Nguyen. &lt;em&gt;Universal Multi-Domain Translation via Diffusion Routers&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Huy Le, Nhat Chung, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Jingkang Yang, and Ngan Le. &lt;em&gt;UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Nghiem Thanh Pham, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Duc-Manh Nguyen, Son Ha Xuan, Nghia Duong-Trung, and Danh Le-Phuoc. &lt;em&gt;SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impact&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Huy Le, Nhat Chung, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Anh Nguyen, and Ngan Le. &lt;em&gt;BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Duc Kieu, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Peng Han, Bin Yang, Christian S. Jensen, and Bac Le. &lt;em&gt;TEAM: Topological Evolution-aware Framework for Traffic Forecasting&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Chenjuan Guo, Ronghui Xu, Bin Yang, Ye Yuan, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Yan Zhao, and Christian S. Jensen. &lt;em&gt;Efficient Stochastic Routing in Path-Centric Uncertain Road Networks&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;David Campos, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Miao Zhang, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;QCore: Data-Efficient, On-Device Continual Calibration for Quantized Models&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Huy Le, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Anh Nguyen, and Ngan Le. &lt;em&gt;WAVER: Writing-style Agnostic Video Retrieval via Distilling Vision-Language Models Through Open-Vocabulary Knowledge&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;David Campos, Miao Zhang, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, and Christian S. Jensen. &lt;em&gt;LightTS: Lightweight Time Series Classification with Adaptive Ensemble Distillation&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tung Kieu&lt;/strong&gt;, Bin Yang, Chenjuan Guo, Christian S. Jensen, Yan Zhao, Feiteng Huang, and Kai Zheng. &lt;em&gt;Robust and Explainable Autoencoders for Time Series Outlier Detection&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Razvan-Gabriel Cirstea, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Xuanyi Dong, Shirui Pan, and Bin Yang. &lt;em&gt;Triformer: Triangular, Variable-Specific Attentions for Long Sequence Multivariate Time Series Forecasting&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Razvan-Gabriel Cirstea, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Shirui Pan, and Bin Yang. &lt;em&gt;Towards Spatio-Temporal Aware Traffic Time Series Forecasting&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;David Campos, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Chenjuan Guo, Feiteng Huang, Kai Zheng, Bin Yang, and Christian S. Jensen. &lt;em&gt;Unsupervised Time Series Outlier Detection with Diversity-Driven Convolutional Ensembles&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;Yan Zhao, Liwei Deng, Xuanhao Chen, Chenjuan Guo, Bin Yang, &lt;strong&gt;Tung Kieu&lt;/strong&gt;, Feiteng Huang, Torben Bach Pedersen, Kai Zheng, and Christian S. Jensen. &lt;em&gt;A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis&amp;ndash;Extended Version&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Services</title>
      <link>https://tungk.github.io/pages/services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tungk.github.io/pages/services/</guid>
      <description>&lt;h2 id=&#34;awards&#34;&gt;&#xD;&#xA;  Awards&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#awards&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Best PC Award in IEEE International Conference on Data Engineering (ICDE)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;conferences&#34;&gt;&#xD;&#xA;  Conferences&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#conferences&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ACM SIGKDD Conference on Knowledge Discovery and Data Mining (SIGKDD)&lt;/li&gt;&#xA;&lt;li&gt;ACM SIGMOD Conference on Management of Data (SIGMOD)&lt;/li&gt;&#xA;&lt;li&gt;Conference on Neural Information Processing Systems (NEURIPS)&lt;/li&gt;&#xA;&lt;li&gt;International Joint Conference on Artificial Intelligence (IJCAI)&lt;/li&gt;&#xA;&lt;li&gt;AAAI Conference on Artificial Intelligence (AAAI)&lt;/li&gt;&#xA;&lt;li&gt;International Conference on Very Large Data Bases (VLDB)&lt;/li&gt;&#xA;&lt;li&gt;ACM Web Conference (TheWebConf)&lt;/li&gt;&#xA;&lt;li&gt;IEEE International Conference on Data Engineering (ICDE)&lt;/li&gt;&#xA;&lt;li&gt;ACM International Conference on Multimedia (MM)&lt;/li&gt;&#xA;&lt;li&gt;ACM International Conference on Information and Knowledge Management (CIKM)&lt;/li&gt;&#xA;&lt;li&gt;IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)&lt;/li&gt;&#xA;&lt;li&gt;ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (SIGSPATIAL/GIS)&lt;/li&gt;&#xA;&lt;li&gt;IEEE International Conference on Big Data (BigData)&lt;/li&gt;&#xA;&lt;li&gt;International Conference on Advanced Data Mining and Applications (ADMA)&lt;/li&gt;&#xA;&lt;li&gt;APWeb-WAIM International Joint Conference on Web and Big Data (APWEB-WAIM)&lt;/li&gt;&#xA;&lt;li&gt;IEEE International Conference on Mobile Data Management (MDM)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;journals&#34;&gt;&#xD;&#xA;  Journals&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#journals&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Journal of Artificial Intelligence Research (JAIR)&lt;/li&gt;&#xA;&lt;li&gt;ACM Transactions on Information Systems (TOIS)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Neural Networks and Learning Systems (TNNLS)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Knowledge and Data Engineering (TKDE)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Signal Processing (TSP)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Intelligent Transportation Systems (TITS)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Network Science and Engineering (TNSE)&lt;/li&gt;&#xA;&lt;li&gt;IEEE Transactions on Industrial Informatics (TII)&lt;/li&gt;&#xA;&lt;li&gt;Data Mining and Knowledge Discovery (DMKD)&lt;/li&gt;&#xA;&lt;li&gt;Pattern Recognition&lt;/li&gt;&#xA;&lt;li&gt;Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning&lt;/li&gt;&#xA;&lt;li&gt;Expert Systems with Applications&lt;/li&gt;&#xA;&lt;li&gt;Neural Processing Letters&lt;/li&gt;&#xA;&lt;li&gt;IEEE Access&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;collaboration&#34;&gt;&#xD;&#xA;  Collaboration&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#collaboration&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Collaborating with &lt;em&gt;TADAA!&lt;/em&gt; (in aSTEP project).&lt;/li&gt;&#xA;&lt;li&gt;Collaborating with the &lt;em&gt;BioX&lt;/em&gt; (in aSTEP project).&lt;/li&gt;&#xA;&lt;li&gt;Collaborating with &lt;em&gt;Huawei&lt;/em&gt; (in Huawei project)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Teaching</title>
      <link>https://tungk.github.io/pages/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tungk.github.io/pages/teaching/</guid>
      <description>&lt;h2 id=&#34;coordination&#34;&gt;&#xD;&#xA;  Coordination&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#coordination&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Software 7 (SW9).&lt;/li&gt;&#xA;&lt;li&gt;Software 9 (SW9).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;courses&#34;&gt;&#xD;&#xA;  Courses&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#courses&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Advanced Algorithms (shared with Prof. Bin Yang and Prof. Chenjuan Guo).&lt;/li&gt;&#xA;&lt;li&gt;Algorithms and Computability (shared with Prof. Bin Yang, Prof. Dalin Zhang, and Prof. Alvaro Torralba).&lt;/li&gt;&#xA;&lt;li&gt;Algorithms and Satisfiability (shared with Prof. Bin Yang, Prof. Dalin Zhang, and Prof. Alvaro Torralba).&lt;/li&gt;&#xA;&lt;li&gt;Introduction to Database Systems (at RMIT University).&lt;/li&gt;&#xA;&lt;li&gt;Programming Bootcamp (at RMIT University).&lt;/li&gt;&#xA;&lt;li&gt;Programming Studio (at RMIT University).&lt;/li&gt;&#xA;&lt;li&gt;Data-intensive Sytems.&lt;/li&gt;&#xA;&lt;li&gt;Specilization Course in Database/Data Mining.&lt;/li&gt;&#xA;&lt;li&gt;Mobile Data and Location-based Services (shared with Prof. Tiantian Liu).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;supervision&#34;&gt;&#xD;&#xA;  Supervision&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#supervision&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Software 4 (SW4).&lt;/li&gt;&#xA;&lt;li&gt;Software 5 (SW5).&lt;/li&gt;&#xA;&lt;li&gt;Software 6 (SW6).&lt;/li&gt;&#xA;&lt;li&gt;Specialization course in Database Technology (SpDT).&lt;/li&gt;&#xA;&lt;li&gt;Master Thesis (shared with Prof. Bin Yang).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;teaching-assistant&#34;&gt;&#xD;&#xA;  Teaching Assistant&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#teaching-assistant&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Algorithms and Data Structures (shared with Sean Bin Yang).&lt;/li&gt;&#xA;&lt;li&gt;Advanced Algorithms (shared with Sean Bin Yang).&lt;/li&gt;&#xA;&lt;li&gt;Algorithms and Computability (shared with Jákup Odssonur Svöðstein).&lt;/li&gt;&#xA;&lt;li&gt;Algorithms and Satisfiability (shared with Jákup Odssonur Svöðstein).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;master-students&#34;&gt;&#xD;&#xA;  Master Students&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#master-students&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;David Campos (co-supervised with Prof. Bin Yang)&lt;/li&gt;&#xA;&lt;li&gt;Mik Christensen (co-supervised with Prof. Bin Yang)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;phd-students&#34;&gt;&#xD;&#xA;  Ph.D. Students&#xD;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#phd-students&#34;&gt;&#xD;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xD;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;David Campos (co-supervised with Prof. Bin Yang)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
